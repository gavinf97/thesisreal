{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224ad7fc-ea62-40e7-8bdf-5b480f94e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRC\n",
      "Read in read data = ['ERR1293545.contigs.fa:11980\\n', 'ERR1293581.contigs.fa:11906\\n', 'ERR1293674.contigs.fa:9888\\n', 'ERR1293738.contigs.fa:25149\\n', 'ERR1293750.contigs.fa:22158\\n', 'ERR1293842.contigs.fa:13263\\n', 'ERR1293878.contigs.fa:18553\\n', 'ERR1293937.contigs.fa:9853\\n']\n",
      "Read in bgc data = ['crc_ERR1293545_results_merged.gbk:26\\n', 'crc_ERR1293581_results_merged.gbk:43\\n', 'crc_ERR1293674_results_merged.gbk:20\\n', 'crc_ERR1293738_results_merged.gbk:108\\n', 'crc_ERR1293750_results_merged.gbk:92\\n', 'crc_ERR1293842_results_merged.gbk:45\\n', 'crc_ERR1293878_results_merged.gbk:19\\n', 'crc_ERR1293937_results_merged.gbk:37\\n']\n",
      "\n",
      "\n",
      "CRC\n",
      "Stripped of newline = ['ERR1293545.contigs.fa:11980', 'ERR1293581.contigs.fa:11906', 'ERR1293674.contigs.fa:9888', 'ERR1293738.contigs.fa:25149', 'ERR1293750.contigs.fa:22158', 'ERR1293842.contigs.fa:13263', 'ERR1293878.contigs.fa:18553', 'ERR1293937.contigs.fa:9853']\n",
      "Stripped of newline = ['crc_ERR1293545_results_merged.gbk:26', 'crc_ERR1293581_results_merged.gbk:43', 'crc_ERR1293674_results_merged.gbk:20', 'crc_ERR1293738_results_merged.gbk:108', 'crc_ERR1293750_results_merged.gbk:92', 'crc_ERR1293842_results_merged.gbk:45', 'crc_ERR1293878_results_merged.gbk:19', 'crc_ERR1293937_results_merged.gbk:37']\n",
      "\n",
      "\n",
      "Normal\n",
      "Read in read data = ['ERR1293525.contigs.fa:11594\\n', 'ERR1293585.contigs.fa:10720\\n', 'ERR1293651.contigs.fa:78430\\n', 'ERR1293662.contigs.fa:17178\\n', 'ERR1293670.contigs.fa:17528\\n', 'ERR1293705.contigs.fa:16366\\n', 'ERR1293710.contigs.fa:20461\\n', 'ERR1293758.contigs.fa:19743\\n']\n",
      "Read in bgc data = ['normal_ERR1293525_results_merged.gbk:30\\n', 'normal_ERR1293585_results_merged.gbk:30\\n', 'normal_ERR1293651_results_merged.gbk:72\\n', 'normal_ERR1293662_results_merged.gbk:46\\n', 'normal_ERR1293670_results_merged.gbk:55\\n', 'normal_ERR1293705_results_merged.gbk:54\\n', 'normal_ERR1293710_results_merged.gbk:70\\n', 'normal_ERR1293758_results_merged.gbk:48\\n']\n",
      "\n",
      "\n",
      "Normal\n",
      "Stripped of newline = ['ERR1293525.contigs.fa:11594', 'ERR1293585.contigs.fa:10720', 'ERR1293651.contigs.fa:78430', 'ERR1293662.contigs.fa:17178', 'ERR1293670.contigs.fa:17528', 'ERR1293705.contigs.fa:16366', 'ERR1293710.contigs.fa:20461', 'ERR1293758.contigs.fa:19743']\n",
      "Stripped of newline = ['normal_ERR1293525_results_merged.gbk:30', 'normal_ERR1293585_results_merged.gbk:30', 'normal_ERR1293651_results_merged.gbk:72', 'normal_ERR1293662_results_merged.gbk:46', 'normal_ERR1293670_results_merged.gbk:55', 'normal_ERR1293705_results_merged.gbk:54', 'normal_ERR1293710_results_merged.gbk:70', 'normal_ERR1293758_results_merged.gbk:48']\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "#Normalisation#\n",
    "###############\n",
    "#data in\n",
    "\n",
    "\n",
    "\n",
    "#Megahit\n",
    "#-CRC!!!\n",
    "\n",
    "#opens file path to CRC read counts and bgc counts\n",
    "with open('/home/gavin/thesis/python_r/1final_data/8mega_work_files/normalisation_stage2/crc_count_data/mega8_crc_fasta_reads.txt') as read_data:\n",
    "    r_data = read_data.readlines() #all in one string\n",
    "with open('/home/gavin/thesis/python_r/1final_data/8mega_work_files/normalisation_stage2/crc_count_data/mega8_crc_gbk_bgcs_count.txt') as bgc_data:\n",
    "    b_data = bgc_data.readlines()\n",
    "\n",
    "#Uncomment to check if ok\n",
    "print('CRC')\n",
    "print('Read in read data = ' + str(r_data))\n",
    "print('Read in bgc data = ' + str(b_data))\n",
    "print('\\n')\n",
    "#crc\n",
    "#strips newline characters in both files\n",
    "r_data1 = []\n",
    "b_data1 = [] \n",
    "\n",
    "print('CRC')\n",
    "for element in r_data:\n",
    "    r_data1.append(element.strip('\\n'))\n",
    "print('Stripped of newline = ' + str(r_data1))\n",
    "\n",
    "for element in b_data:\n",
    "    b_data1.append(element.strip('\\n'))\n",
    "print('Stripped of newline = ' + str(b_data1))\n",
    "print('\\n')\n",
    "\n",
    "#-Normal!!!\n",
    "#opens file path to Normal read counts and bgc counts\n",
    "print('Normal')\n",
    "with open('/home/gavin/thesis/python_r/1final_data/8mega_work_files/normalisation_stage2/normal_count_data/mega8_normal_fasta_reads.txt') as read_data:\n",
    "    #bgcs_list = bgc.readlines() #all in one list, each line an item string\n",
    "    r_norm_data = read_data.readlines() #all in one string\n",
    "print('Read in read data = ' + str(r_norm_data))\n",
    "with open('/home/gavin/thesis/python_r/1final_data/8mega_work_files/normalisation_stage2/normal_count_data/mega8_normal_gbk_bgcs_count.txt') as bgc_data:\n",
    "    b_norm_data = bgc_data.readlines()\n",
    "print('Read in bgc data = ' + str(b_norm_data))\n",
    "print('\\n')\n",
    "\n",
    "#NORMAL\n",
    "#strip newline\n",
    "r_norm_data1 = []\n",
    "b_norm_data1 = [] \n",
    "\n",
    "print('Normal')\n",
    "for element in r_norm_data:\n",
    "    r_norm_data1.append(element.strip('\\n'))\n",
    "print('Stripped of newline = ' + str(r_norm_data1))\n",
    "\n",
    "for element in b_norm_data:\n",
    "    b_norm_data1.append(element.strip('\\n'))\n",
    "print('Stripped of newline = ' + str(b_norm_data1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d765dc2-1ca3-4a3a-aa10-883f7b791a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRC Values \n",
      "\n",
      "CRC BGCs = [26, 43, 20, 108, 92, 45, 19, 37]\n",
      "CRC Total BGCs = 390\n",
      "\n",
      "CRC Reads = [11980, 11906, 9888, 25149, 22158, 13263, 18553, 9853]\n",
      "CRC Total Reads = 122750\n",
      "\n",
      "\n",
      "\n",
      "Normal Values \n",
      "\n",
      "Normal BGCs = [30, 30, 72, 46, 55, 54, 70, 48]\n",
      "Normal Total BGCs = 405\n",
      "\n",
      "\n",
      "Normal Reads = [11594, 10720, 78430, 17178, 17528, 16366, 20461, 19743]\n",
      "Normal Total Reads = 192020\n",
      "\n",
      "Normalised data BGC counts:\n",
      "[21.702838063439064, 36.116243910633294, 20.226537216828476, 42.94405344148873, 41.51999277913169, 33.92897534494458, 10.240931385759714, 37.55201461483812]\n",
      "[25.875452820424357, 27.98507462686567, 9.180160652811423, 26.77843753638375, 31.378366042902787, 32.99523402175242, 34.21142661648991, 24.31241452666768]\n",
      "\n",
      "Sample Names\n",
      "CRC: ['ERR1293545', 'ERR1293581', 'ERR1293674', 'ERR1293738', 'ERR1293750', 'ERR1293842', 'ERR1293878', 'ERR1293937']\n",
      "Normal: ['ERR1293525', 'ERR1293585', 'ERR1293651', 'ERR1293662', 'ERR1293670', 'ERR1293705', 'ERR1293710', 'ERR1293758']\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#PARSING##\n",
    "##########\n",
    "\n",
    "\n",
    "#CRC\n",
    "#bgcsparse\n",
    "print('CRC Values \\n')\n",
    "numbers_bgcs = []\n",
    "for sample in b_data1:\n",
    "    for word in str(sample).split(':'):\n",
    "           if word.isdigit():\n",
    "                  numbers_bgcs.append(int(word))\n",
    "print('CRC BGCs = ' + str(numbers_bgcs))\n",
    "#bgcs total\n",
    "print('CRC Total BGCs = ' + str(sum(numbers_bgcs)) + '\\n')\n",
    "\n",
    "#readsparse\n",
    "numbers_reads =[]\n",
    "for sample in r_data1:\n",
    "    for word in str(sample).split(':'):\n",
    "           if word.isdigit():\n",
    "                  numbers_reads.append(int(word))\n",
    "\n",
    "print('CRC Reads = ' + str(numbers_reads))\n",
    "#reads total\n",
    "print('CRC Total Reads = ' + str(sum(numbers_reads)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "#Normal\n",
    "#bgcsparse\n",
    "print('\\nNormal Values \\n')\n",
    "numbers_norm_bgcs = []\n",
    "for sample in b_norm_data1:\n",
    "    for word in str(sample).split(':'):\n",
    "           if word.isdigit():\n",
    "                  numbers_norm_bgcs.append(int(word))\n",
    "print('Normal BGCs = ' + str(numbers_norm_bgcs))\n",
    "#bgcs total\n",
    "print('Normal Total BGCs = ' + str(sum(numbers_norm_bgcs)))\n",
    "print('\\n')\n",
    "\n",
    "#readsparse\n",
    "numbers_norm_reads =[]\n",
    "for sample in r_norm_data1:\n",
    "    for word in str(sample).split(':'):\n",
    "           if word.isdigit():\n",
    "                  numbers_norm_reads.append(int(word))\n",
    "print('Normal Reads = ' + str(numbers_norm_reads))\n",
    "#reads total\n",
    "print('Normal Total Reads = ' + str(sum(numbers_norm_reads)))\n",
    "\n",
    "\n",
    "\n",
    "#Normalised BGC count data\n",
    "from operator import truediv\n",
    "bgc_crc = list(map(truediv, numbers_bgcs, numbers_reads))\n",
    "normalised_crc_bgc = [i * 10000 for i in bgc_crc]\n",
    "bgc_norm = list(map(truediv, numbers_norm_bgcs, numbers_norm_reads))\n",
    "normalised_norm_bgc = [i * 10000 for i in bgc_norm]\n",
    "\n",
    "print('\\n'+'Normalised data BGC counts:')\n",
    "print(normalised_crc_bgc)\n",
    "print(normalised_norm_bgc)\n",
    "\n",
    "sum_crc_bgcs_normalised = (sum(normalised_crc_bgc))\n",
    "sum_norm_bgcs_normalised = (sum(normalised_norm_bgc))\n",
    "\n",
    "print('\\nSample Names')\n",
    "#Extracts sample names crc\n",
    "sample_names_crc = []\n",
    "for sample in r_data1:\n",
    "    for word in str(sample).split('.'):\n",
    "        if word.startswith('ER'):\n",
    "            sample_names_crc.append(word)\n",
    "print('CRC: ' + str(sample_names_crc))\n",
    "#Extracts sample names normal          \n",
    "sample_names_normal = []\n",
    "for sample in r_norm_data1:\n",
    "    for word in str(sample).split('.'):\n",
    "        if word.startswith('ER'):\n",
    "            sample_names_normal.append(word)\n",
    "print('Normal: ' + str(sample_names_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58ebd6-edb9-4602-87f5-17983cc25e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract normalised and non -normalised csv values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f4d240e-8cd3-40b1-b26c-a7230f7d6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write data to csv for use in R\n",
    "import csv\n",
    "\n",
    "with open('/home/gavin/thesis/python_r/1final_data/8mega_work_files/normalisation_stage2/mega8_count_data.csv', 'w', newline='') as csv_data:\n",
    "    wr = csv.writer(csv_data, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(['CRC_Sample','CRC_Reads','CRC_BGCs','CRC_normalised_BGCs','NORM_Sample','NORM_Reads','NORM_BGCs','NORM_normalised_BGCs'])\n",
    "    for w in range(8):\n",
    "            wr.writerow([sample_names_crc[w],numbers_reads[w],numbers_bgcs[w],normalised_crc_bgc[w],sample_names_normal[w],numbers_norm_reads[w],numbers_norm_bgcs[w],normalised_norm_bgc[w]])\n",
    "\n",
    "#file.close()\n",
    "    \n",
    "#MAYBE REWRITE TO TWO SEP FILES AND MERGE FOR PLOTTING LIKE PAST PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c02121-379b-4a1d-aefe-3f3e01b4b1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
